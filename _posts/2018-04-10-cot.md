---
layout:   research
title:    NIPS-2018: CoT: Cooperative Training for Generative Modeling of Discrete Data
category: submissions
---

# Abstract
<blockquote class="abstract mathjax">
<span class="descriptor">Abstract:</span> We propose Cooperative Training (CoT) for training generative models that
measure a tractable density function for target data. CoT coordinately trains a
generator $G$ and an auxiliary predictive mediator $M$. The training target of
$M$ is to estimate a mixture density of the learned distribution $G$ and the
target distribution $P$, and that of $G$ is to minimize the Jensen-Shannon
divergence estimated through $M$. CoT achieves independent success without the
necessity of pre-training via Maximum Likelihood Estimation or involving
high-variance algorithms like REINFORCE. This low-variance algorithm is
theoretically proved to be unbiased for both generative and predictive tasks.
We also theoretically and empirically show the superiority of CoT over most
previous algorithms, in terms of generative quality and diversity, predictive
generalization ability and computational cost.
</blockquote>
# Arxiv Link

https://arxiv.org/abs/1803.07133

# Status

Rejected

