\documentclass{article}
    \usepackage[T1]{fontenc}
    \usepackage[utf8]{inputenc}
    \usepackage[margin=1in]{geometry}
    
    
    \newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
    \newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}
    
    \makeatletter% since there's an at-sign (@) in the command name
    \renewcommand{\@maketitle}{%
      \parindent=0pt% don't indent paragraphs in the title block
      \centering
      {\Large \bfseries\textsc{\@title}}
      \HRule\par%
      \textit{\@author \hfill \@date}
      \par
    }
    \makeatother% resets the meaning of the at-sign (@)
    
    \title{Personal Statement}
    \author{Sidi Lu}
    \date{Ph.D. Applicant}
    
    \begin{document}
      \maketitle% prints the title block
      \thispagestyle{empty}
      \vspace{35pt}
    
      % When I was only a little boy, I always wanted a friend to chat with. Out of innocent greed, I expect he/she to understand every single piece of idea in my head, with endless passion and patience. I kept looking for such a friend, ended up with understanding a fact that, it's hard for humans to understand each other, and that understanding me is not an exception. From then on, I started to imagine that what if there is a machine that does this better than me and anyone else, which can be used to help humans to better communicate with each other. By better understanding what others need and care, everyone would get a chance to live in a better world, where no one shall ever suffer from solitude. During those old days, my adventure with my computer got me really fascinated with this tiny machine. After I had a rudimentary grasp of programming skills, a new perspective to understand intelligence has gradually formed in my mind. Since then, computer science has always been my dream major. 

      The ability to model, interpret and manipulate the structure of sequential, discrete data is important in many applicational tasks, including unconditional natural language generation, dialogue systems (chatbots), neural machine translation, personalized advertisement and so on. My research background basically lie in the field of the fundamental problem of the area, i.e. improved training of auto-aggressive models for sequential, discrete data. I'm also open to applicational researches in this field and/or other representation learning researches for sequential discrete data.

      I'm well educated in the general field of computer science. During my school life in middle school and high school, I spent most of my spare time writing programs to address any problem I may see. I participated in the Chinese National Olympiad in Informatics in Provinces (NOIp) and won the first class prize in NOIp 2013 and 2014. It is a true test of my programming skills. After entering Shanghai Jiao Tong University (one of the top 5 colleges in China), I got accepted as a member of the ACM Honors Class because of such a positive recognition of my ability and my enthusiasm for computer science. 

      % Although the burden of schoolwork is heavy, as that most Chinese students would have to face the pressure of the College Entrance Examination, the success in NOIp encouraged me to know more about computer science.
      % I took Professor Weinan Zhang's Machine Learning course in the second term of my sophomore year. During the course, all attendants are required to join two in-class competitions. The goal of the first competition is to solve a binary text classification problem. I studied really hard on this task, with a lot of empirical attempts using various statistical machine learning approaches. At the end of the competition, I won the 3rd place out of 34 participants. Another competition is to design a recommendation system. I won the 2nd place out of 31 participants. Because of my outstanding achievements, I was awarded 100/100 for this course. This honor encouraged me to explore more in the field of machine learning.
      
      I have a good understanding of what I'm currently working on and I have had a few publications.

      After I've finished my sophomore courses, I joined the APEX data and knowledge management lab of SJTU as an undergraduate member, supervised by Professor Weinan Zhang and Professor Yong Yu. During that summer vacation, I had my first research internship in APEX. The atmosphere of communication is quite good in APEX. After each day's lecture, Weinan would chair a brief discussion with lab members, during which students are encouraged to share their comments and thoughts. Such brainstorm encouraged me to think deeper about machine learning, establishing a reliable knowledge base for me to support further research. 

      At the very beginning, my research mainly focused on reinforcement learning/inverse reinforcement learning, as well as their application on improving sequence modeling algorithms and vice versa. The most interesting point of improving sequence modeling algorithms is based on an analysis on the flaw of training auto-aggressive models via Maximum Likelihood Estimation. To be more specific, when trained via MLE, at each time step of the modeling process, the model is trained on the data distribution of input prefixes and tested on a different distribution of input prefixes, namely, the learned distribution. This discrepancy implies that in the training stage, the model is never exposed to its own errors and thus in the test stage, the errors made along the way will quickly accumulate. This causes auto-aggressive models sometimes act strange, and are not robust to novel test examples.

      To address this problem, APEX lab proposed SeqGAN in 2016. My job was originally to follow SeqGAN's footprints and to find out possible improvements on it. My first attempt at actually submitting a paper to a conference took place later that summer. I joined the group of LeakGAN. In this attempt, we designed a hierarchical architecture for the text generation problem, with a novel training algorithm to address the optimization of it. The original idea of the work is to address the gradient vanishing problem in training language GANs. When a discriminator is much stronger that the generator, although the discriminator can successfully classify the real-fake samples, as almost all generated sequences are scored as almost zero, the good discriminator is thus not able to guide the generator. To address this problem, one idea is to manipulated the embedded latent space produced by the discriminator. Think of one way to manipulate the embeddings of sequences (namely, ``leaked information'') during the generation process, we can intuitively imagine that this will improve the training process. When I joined the group, the naive version of the algorithm suffers from the instability during the adversarial training stage. By analyzing the obtained expected reward during training, I found that the numerical variance of the reward signal may be the major factor of such instability. Inspired by batch normalization, I proposed bootstrapped rescaled activation, which places a prior on the obtained rewards in each time step of the sampled batch of sequence. This module turns out to remarkably stabilize the training process, making our algorithm more robust to hyperparameter settings. After weeks of hard working, our paper ``Long text generation via adversarial training with leaked information'' got accepted as a conference poster paper by AAAI-2018.
      
      After the publication of LeakGAN, I start to study another open problem in this field. There are some blind spots in language GANs' behavior. The discrepancy of getting more realistic samples and fully covering the data mode has been well known as a flaw called ``mode-collapse'' for many adversarially-trained generative models. Specifically for language GANs, because of the naive REINFORCE algorithm incorporated to optimize a non-differentiable target, the ``mode-collapse'' problem is even worse as a result of the variance of the algorithm. To address this problem, at first I paid much attention to better gradient estimators as better alternatives to replace REINFORCE. However, I gradually realize that this is too far from being an essential solution for this. The sequence modeling problem has its speciality. Getting stuck in a more general set of problems seem not to show what is the essence of the one specific problem. Meanwhile, new GAN variants like Wasserstein GAN was proposed and soon attracted much attention in the deep learning community. These algorithms think of GANs as an indirect optimization algorithm of several different density integral functions. For example, GAN optimizes JSD, and the mode collapse/gradient vanishing problems are somehow consequences of the properties of unconstrained JSD. Wasserstein GAN optimizes Wasserstein-1 (aka Earth Mover) Distance, making it possible for such algorithm to deal with most of GAN's original flaws. Such analysis enlightened me, driving me to think more from the aspects of measurements between different probability density functions. I started to study more about the properties of different distribution distances/divergences.

      The production of the resulting idea seems to be a little bit dramatic. That was an early morning in March this year, a seemingly nonsensical idea came into my mind, rousing me from the dream. I asked myself, ``do we really need adversary?'' Original GANs' success come from the symmetry of Jensen-Shannon divergence (which is actually GANs' objective) to some extent. If we were actually able to achieve the optimization of JSD for a text generator, it doesn't matter how we do this. That is to say, adversarial training is not the only option to improve an auto-aggressive model. This idea led to the paper ``CoT: Cooperative Training for Generative Modeling of Discrete Data''. Cooperative Training flips the original min-max game of GANs into a max-max optimization problem. In a typical framework of CoT, the model includes two isomorphic modules, namely the generator and the mediator. Both of the modules are auto-aggressive models. The mediator learns to model mixed samples, half of which are sampled from the generator and the other half are real samples. The generator learns to reduce the total cost for a mediator to build a consistent model for the mixed samples. Finally, the algorithm converges to the minimization of JSD, and then both the generator and the mediator converges to the target distribution. When writting the paper, as I'm already quite familiar with the paradigms of writing a paper in this field, including how to arrange the introduction, how to design and perform the experiments and how to do the theoretical analysis, it took me only 5 days to finish the first draft of the paper. After months of careful polishing, the paper was submitted to ICLR 2019, and got a review of 7/7/7. 

      I am a visiting student at Professor Joshua B. Tenenbaum's lab, for a half-year research internship in Massachusetts Institute of Technology. The internship started on July 4th, 2018. My topic is about neurally-guided Bayesian Program Learning, especially using such techniques to help improve learning system's combinatorial generalization ability. As an specific task of the problem, when we are dealing with Visual Question Answering problems, one solution is to first parse out the logic of the query and then use a symbolic execution process to obtain the answer. During the process, if we directly train a program parser that converts natural language descriptions into their structural form, when the training data is simple and logically shallow, the model may not generalize well on complicated, logically deep test queries. My current work focuses on improving the ability of such models. The story of the algorithm consists of two parts. One is that when we are informed about several candidate production rules to decompose the processed problem into sub-tasks. The only problem is to determine which one to apply in each time step. One typical problem in this class is probabilistic matrix factorization. The other one is that we have to jointly learn both the decomposition and the choice of rules, which is much harder. For instance, the parsing of structural forms for queries in VQA tasks lies in such a class. My attempts basically focus on designing naturally-compositional architectures for such a task. For the first class of problem, we design a predictor network for guided search of the compositional structure. For the second class of problems, we aim to propose better formulation and regularization for neural networks, in order to improve their generalization abilities. The paper is still in progress. 

      As for future plans, I wish to do more study on both the practice and theory of generative models and reinforcement learning/inverse reinforcement learning systems. I believe that my research experience, education background and psychological quality would keep me productive in my graduate research life.

    \end{document}
