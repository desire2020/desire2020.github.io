\documentclass{article}
    \usepackage[T1]{fontenc}
    \usepackage[utf8]{inputenc}
    \usepackage[margin=1in]{geometry}
    
    
    \newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
    \newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}
    
    \makeatletter% since there's an at-sign (@) in the command name
    \renewcommand{\@maketitle}{%
      \parindent=0pt% don't indent paragraphs in the title block
      \centering
      {\Large \bfseries\textsc{\@title}}
      \HRule\par%
      \textit{\@author \hfill \@date}
      \par
    }
    \makeatother% resets the meaning of the at-sign (@)
    
    \title{Statement of Purpose}
    \author{Sidi Lu}
    \date{Ph.D. Applicant}
    
    \begin{document}
      \maketitle% prints the title block
      \thispagestyle{empty}
      \vspace{35pt}
    
      When I was only a little boy, I always wanted a friend to chat with. Out of innocent greed, I expect he/she to understand every single piece of idea in my head, with endless passion and patience. I kept looking for such a friend, ended up with understanding a fact that, it's hard for humans to understand each other, and that understanding me is not an exception. From then on, I started to imagine that what if there is a machine that does this better than me and anyone else, which can be used to help humans to better communicate with each other. By better understanding what others need and care, everyone would get a chance to live in a better world, where no one shall ever suffer from solitude. During those old days, my adventure with my computer got me really fascinated with this tiny machine. After I had a rudimentary grasp of programming skills, a new perspective to understand intelligence has gradually formed in my mind. Since then, computer science has always been my dream major. 
      
      During my school life in middle school and high school, I spent most of my spare time writing programs to address any problem I may see. I participated in the Chinese National Olympiad in Informatics in Provinces (NOIp) and won the first class prize in NOIp 2013 and 2014. Although this experience did not help a lot when I applied for college, it is a true test of my programming skills. Although the burden of schoolwork is heavy, as that most Chinese students would have to face the pressure of the College Entrance Examination, the success in NOIp encouraged me to know more about computer science. After entering Shanghai Jiao Tong University (one of the top 5 colleges in China), I got accepted as a member of the ACM Honors Class because of such a positive recognition of my ability and my enthusiasm for computer science. 

      % I took Professor Weinan Zhang's Machine Learning course in the second term of my sophomore year. During the course, all attendants are required to join two in-class competitions. The goal of the first competition is to solve a binary text classification problem. I studied really hard on this task, with a lot of empirical attempts using various statistical machine learning approaches. At the end of the competition, I won the 3rd place out of 34 participants. Another competition is to design a recommendation system. I won the 2nd place out of 31 participants. Because of my outstanding achievements, I was awarded 100/100 for this course. This honor encouraged me to explore more in the field of machine learning.
      
      After I've finished my sophomore courses, I joined the APEX data and knowledge management lab of SJTU as an undergraduate member, supervised by Professor Weinan Zhang and Professor Yong Yu. During that summer vacation, I had my first research internship in APEX. When I first joined the lab, I am suggested to learn the basic theory of deep reinforcement learning from Professor David Silver's online course. After each days' lecture, Weinan would chair a brief discussion with all undergraduate members of the lab, during which students are encouraged to share their comments on every lecture. Such brainstorm encouraged me to think deeper about reinforcement learning, establishing a reliable knowledge base for me to support further research. 

      Since then, my research mainly focuses on reinforcement learning/inverse reinforcement learning, as well as their application on improving sequence modeling algorithms and vice versa. The most interesting point of improving sequence modeling algorithms is based on an analysis on the flaw of training auto-aggressive models via Maximum Likelihood Estimation. To be more specific, when trained via MLE, at each time step of the modeling process, the model is trained on the data distribution of input prefixes and tested on a different distribution of input prefixes, namely, the learned distribution. This discrepancy implies that in the training stage, the model is never exposed to its own errors and thus in the test stage, the errors made along the way will quickly accumulate. This causes auto-aggresive models sometimes act strange, and are not robust to novel test examples.

      To address this problem, APEX lab proposed SeqGAN in 2016. My job was originally to follow SeqGAN's footprints and to find out possible improvements on it. My first attempt at actually submitting a paper to a conference took place later that summer. I joined the group of LeakGAN. In this attempt, we designed a hierarchical architecture for the text generation problem, with a novel training algorithm to address the optimization of it. When I joined the group, the naive version of the algorithm suffers from the instability during the adversarial trainin stage. By analyzing the obtained expected reward during training, I found that the numerical variance of the reward signal may be the major factor of such instability. Inspired by batch normalization, I proposed bootstrapped rescaled activation, which places a prior on the obtained rewards in each time step of the sampled batch of sequence. This module turns out to remarkably stabilize the training process, making our algorithm more robust to hyperparameter settings. Because of my contribution, when we started to work on the paper, I became the second author of the paper. After weeks of hard working, our paper ``Long text generation via adversarial training with leaked information'' got accepted as a conference poster paper by AAAI-2018. When we were notified of the acceptance, I felt so happy, for all my efforts are positively recognized.
      
      The success of the first attempt did not stop me from exploring more in this field. Although LeakGAN successfully passed the peer review, there are still some blind spot in the model's bahavior. The discrepancy of getting more realistic samples and fully covering the data mode has been well known as a flaw called ``mode-collapse'' for all adversarially-trained generative models then. LeakGAN is not an exception. Because of the REINFORCE algorithm which is incorporated in LeakGAN's training for non-differentiable optimization, the ``mode-collapse'' problem is even worse if without corresponding operation. In the original version of LeakGAN, we alleviate this problem by incorporating maximum likelihood estimation epochs after every 3\~5 adversarial epochs. However, this solution is too technical. I always believed there is a better solution for this, as I started to think about it as soon as the LeakGAN project is finished.

      The process of the study was never going smoothly. At first I paid much attention to better gradient estimators as better alternatives to replace REINFORCE. However, I gradually realize that this is too far from being an essential solution for this. The sequence modeling problem has its speciality. If we always get stuck in some more general problems, we may never get to know what is the key point of the difficulties of one specific problem. When such consideration came into my mind, meanwhile, Wasserstein GAN was proposed and soon attracted much attention in the deep learning community. The analysis of why a typical GAN often fails to converge and have collapsed mode enlightened me, driving me to think more from the aspects of measurements between different probability density functions. I started to study more about the properties of different distribution distances/divergences. I began to attempt to assemble all of my thoughts into a paper since then.

      This process was long and tortuous. I had expected that the paper should be ready for ICML 2018 submission, but neccessary theoretical analysis had never been ready by then. Although I felt a little bit frustrated, I never give up. The wish to find a perfect solution to the problem occupied every corner of my mind, got me working and thinking day and night.

      Hard work pays off. I remember that was an early morning in March this year, a seemingly nonsensical idea came into my mind, rousing me from the dream. I asked myself, ``do we really need text GANs?'' In my opinion, original GANs' success come from the symmetry of Jensen-Shannon divergence (which is actually GANs' objective) to some extend. If we were actually able to realize the optimization of JSD for a text generator, it doesn't matter how we do this. That is to say, adversarial training is not the only unbiased option to improve the training of an auto-aggresive model. This idea led to the paper ``CoT: Cooperative Training for Generative Modeling of Discrete Data''. Before the creation of the paper, I had participated in the creation of LeakGAN. I'm very familiar with the blueprint of writing a paper in this field, including how to arrange the introduction, how to design and perform the experiments and how to do the theoretical analysis. It took me only 5 days to finish the first draft of the paper, as the properties of the proposed algorithm is quite good and therefore I didn't waste much time on hyper-parameter tuning. After months of careful polishing, the paper was submitted to ICLR 2019, and got a review of 7/7/7. 

      I was invited by Professor Joshua B. Tenenbaum from Massachusetts Institute of Technology for a half-year research internship. The internship started on July 4th, 2018. My topic is about neurally-guided Bayesian Program Learning, especially using such techniques to help improve learning system's combinatorial generalization ability. As an specific task of the problem, when we are dealing with Visual Question Answering problems, one solution is to first parse out the logic of the query and then use a symbolic execution process to obtain the answer. During the process, if we directly train a program parser that converts natural language descriptions into their structural form, when the training data is simple and logically shallow, the model may not generalize well on complicated, logically deep test queries. My current work focuses on improving the ability of such models. I am still working on it, hopefully to get some positive results for the coming ICML.

      As for the future plan, I wish to do more study on both the practice and theory of reinforcement learning/inverse reinforcement learning. I believe that my research experience, education background and psychological quality would keep me productive in my guaduate research life.

    \end{document}
